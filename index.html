<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>CSE555 Final Project - Automatic Image Colorization by SuperMonanana</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">CSE555 Final Project - Automatic Image Colorization</h1>
      <h2 class="project-tagline">Mengyan Li &amp; Yu He</h2>
      <a href="https://github.com/SuperMonanana/ImageColorization" class="btn">View on GitHub</a>
      <a href="https://github.com/SuperMonanana/ImageColorization/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/SuperMonanana/ImageColorization/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h3>
<a id="abstract" class="anchor" href="#abstract" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Abstract</strong>
</h3>

<p>This project focus on automatic image colorization given a greyscale input image. Different from <a href="http://www.cs.huji.ac.il/%7Eyweiss/Colorization/">Levin et al.'s</a> approach, and <a href="http://mrl.nyu.edu/projects/image-analogies/">Image Analogies</a> which rely on user interaction, this project implement a fully automatic colorization method proposed in <a href="http://vision.cs.illinois.edu/projects/lscolor/largescale_automatic_colorization.pdf">Large-scale Learning</a> which exploits a LEARCH framework to train a quadratic objective function in the chromaticity maps and then colorize the image by minimize this objective function. We modified their code by pruning the regression tree to improve the efficiency and avoid overfitting, and we experiment different parameters, features and histogram correction method. </p>

<hr>

<h3>
<a id="best-result" class="anchor" href="#best-result" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Best result</strong>
</h3>

<p>The left are our results, the right are the ground truth.</p>

<p><img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/best_result.tif" alt=""> <img src="https://github.com/SuperMonanana/ImageColorization/blob/master/data/c.png?raw=true" alt="ground truth"> </p>

<p><img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/theirdata.tif" alt=""> <img src="https://github.com/SuperMonanana/ImageColorization/blob/master/data/colorBeach.png?raw=true" alt=""></p>

<p><img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/campus2good.tif" alt="">
<img src="https://github.com/SuperMonanana/ImageColorization/blob/master/data/color_resize.png?raw=true" alt=""></p>

<hr>

<h3>
<a id="problem-definition" class="anchor" href="#problem-definition" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Problem definition</strong>
</h3>

<p>In this project, the input is greyscale image, and the output is the corresponding colorized image. We will also include ground truth image for comparison.</p>

<p>We have the input grey-level image and wish to infer the set of color layers. Our goal is to learn a quadratic optimization problem in the set of color layers. The coefficients of the objective function are conditioned on image features, using a random forest of regression tree. Images are then colorized by minimizing this objective function.</p>

<hr>

<h3>
<a id="related-work" class="anchor" href="#related-work" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Related Work</strong>
</h3>

<p>This project is an exploration of Aditya Deshpande, Jason Rock and David Forsyth. <em><strong>Learning Large-Scale Automatic Image Colorization.</strong></em> In ICCV, Dec 2015.</p>

<hr>

<h3>
<a id="algorithm" class="anchor" href="#algorithm" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Algorithm</strong>
</h3>

<p>We learn an objective function and optimize it to get the correct colorization. We write vectors as b(I,u) and matrices as W(I,u) for pixels u. I is the input grey-level image and c is the set of color layers we wish to infer, rearranged into a vector.</p>

<p><img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/theta.tiff" alt=""></p>

<p><img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/objective%20fcn.tiff" alt=""> </p>

<p><img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/margin.tiff" alt=""></p>

<p>H is for the margin. We represent W and b as a sum over regression trees. For time reason, we only do training and testing on one specific scene.</p>

<p>Basically we followed the code of our reference paper, but we had some attempts in several areas to make a better prediction.</p>

<p><strong>1. Histogram correction</strong></p>

<p>Desired target histogram is modeled as Gaussian mixture model and the number of components are equal to the modes obtained by performing mean-shift clustering modes in the histogram of the target images. Then corresponding modes in the histogram of source images are found with known M components of the target histogram and source histogram. In the paper, histogram correction is achieved using the scene specific mean histogram (normalized from training data). 9 noise images together with the one training image are used to compute the mean histogram. We add a fraction of ground-truth histogram from least variation training set so that noisier training images have less impact on test theme result.</p>

<p>The left uses mean histogram, the middle applies our modified histogram correction method, and the right is the ground truth.</p>

<p><img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/test_1_recon_color-hist_1-1.tif" alt=""> <img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/test_1_recon_color-gt_hist_2-1.tif" alt=""> <img src="https://github.com/SuperMonanana/ImageColorization/blob/master/data/colorbeach.png?raw=true" alt=""> </p>

<p><strong>2. Regression features</strong></p>

<p>Split features determine the splits in regression tree which provide description for the classification of pixels with similar characteristics. Regression features are used as predictors which embody properties of the neighborhood and exhibit a strong correlation to the color. 
In the paper, regression features compose texture plus global image features (top pyramid grayscale image intensity) which occasionally brings to bad outcome due to large variation of lightness in image sets as we speculate. Therefore we dropped global image features, leave merely texture image features and obtained better results.</p>

<p>We apply this histogram method and get our first best result of campus, however when we use mean histogram as in the paper, the result is as following. Obviously, our method improve the accuracy of prediction.</p>

<p><img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/meanhist.tif" alt=""></p>

<p><strong>3. LEARCH objective function and the Bhattacharyya distance</strong></p>

<p>The final objective function is a weighted sum of LEARCH objective function and the Bhattacharyya distance which ensures spatial coherence while performing histogram correction. The complete objective function denoted as: bDist = bDist + lambda.*bLearch. Adjusting  influences this trade-off as bigger provides steeper color variation which displayed below.</p>

<p>Lambda=0.5, 5(the original setting in the paper), 50 are applied in the following results. Large lambda prevents modification of colors by histogram correction.</p>

<p><img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/lambda0.5.tif" alt=""> <img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/lambda5.tif" alt=""> <img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/lambda50.tif" alt=""></p>

<p>Here is the ground truth:</p>

<p><img src="https://github.com/SuperMonanana/ImageColorization/blob/master/data/colorbeach.png?raw=true" alt=""></p>

<hr>

<h3>
<a id="analysis" class="anchor" href="#analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Analysis</strong>
</h3>

<p>Failed case is like this from which we can see the limit of this method.
<img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/campusfail.tif" alt=""> <img src="https://github.com/SuperMonanana/ImageColorization/blob/master/data/color_failresize.png?raw=true" alt=""> </p>

<p>We suppose it is difficult for this method to predict more complex picture with more depth of field because it is harder to extract features that special enough to represents a patch in regions with more depth which is usually smaller. </p>

<p>Also from the successful cases in Best Results section, we found that the performance is always better when predicting the sky because of the bigger contrast between sky and the other parts of the image, which should reflect the grey-image intensity as it is an important split feature. Therefore, this method is hard for distinguishing similar colors.</p>

<p>Some failed case looks aesthetic although its prediction is relatively wrong.
<img src="https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/tricky.tif" alt=""> <img src="https://github.com/SuperMonanana/ImageColorization/blob/master/data/tricky_gt.jpg?raw=true" alt=""></p>

<p>This case illustrates that the luminance could have a big impact on the result and therefore we suppose it would give better result if we balance the brightness of all training images first.</p>

<p>The other limitation concerns all machine learning problem is the out-of-dataset bias. Therefore, the larger scale training data could produce better result. </p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/SuperMonanana/ImageColorization">CSE555 Final Project - Automatic Image Colorization</a> is maintained by <a href="https://github.com/SuperMonanana">SuperMonanana</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
