{
  "name": "CSE555 Final Project - Automatic Image Colorization",
  "tagline": "Mengyan Li & Yu He",
  "body": "### **Abstract**\r\nThis project focus on automatic image colorization given a greyscale input image. Different from [Levin et al.'s](http://www.cs.huji.ac.il/%7Eyweiss/Colorization/) approach, and [Image Analogies](http://mrl.nyu.edu/projects/image-analogies/) which rely on user interaction, this project implement a fully automatic colorization method proposed in [Large-scale Learning](http://vision.cs.illinois.edu/projects/lscolor/largescale_automatic_colorization.pdf) which exploits a LEARCH framework to train a quadratic objective function in the chromaticity maps and then colorize the image by minimize this objective function. We modified their code by pruning the regression tree to improve the efficiency and avoid overfitting, and we experiment different parameters, features and histogram correction method. \r\n\r\n***\r\n### **Best result**\r\nThe left are our results, the right are the ground truth.\r\n\r\n![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/best_result.tif) ![ground truth](https://github.com/SuperMonanana/ImageColorization/blob/master/data/c.png?raw=true) \r\n\r\n\r\n***\r\n### **Problem definition**\r\nIn this project, the input is greyscale image, and the output is the corresponding colorized image. We will also include ground truth image for comparison.\r\n\r\nWe write vectors as b and matrices as W. I is the input grey-level image and c is the set of color layers we wish to infer, rearranged into a vector. Our goal is to learn a quadratic optimization problem in c. The coefficients of the objective function are conditioned on image features, using a random forest of regression tree. Images are then colorized by minimizing this objective function.\r\n***\r\n### **Related Work**\r\n\r\nThis project is an exploration of Aditya Deshpande, Jason Rock and David Forsyth. _**Learning Large-Scale Automatic Image Colorization.**_ In ICCV, Dec 2015.\r\n\r\n***\r\n### **Algorithm**\r\nWe basically followed the structure of our reference paper, but we made some improvements to achieve better output image quality and faster reconstruction speed.\r\n\r\n**1. Histogram correction**\r\n\r\nDesired target histogram is modeled as Gaussian mixture model and the number of components are equal to the modes obtained by performing mean-shift clustering modes in the histogram of the target images. Then corresponding modes in the histogram of source images are found with known M components of the target histogram and source histogram. In the paper, histogram correction is achieved using the scene specific mean histogram (normalized from training data). We add a fraction of ground-truth histogram from least variation training set so that multi-scene training images have less impact on specific theme result.\r\n\r\nThe left applied mean histogram, the middle applied our modified histogram correction method, and the right is the ground truth.\r\n \r\n![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/test_1_recon_color-hist_1-1.tif) ![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/test_1_recon_color-gt_hist_2-1.tif) ![](https://github.com/SuperMonanana/ImageColorization/blob/master/data/color.png?raw=true)\r\n\r\n**2. Parameter experiment**\r\n\r\n(1) maxdepth\r\n\r\nMaxdepth is the parameter used to describe the length of decision tree. As we increase decision tree, learning time is slightly longer, but quality of result image is also better.\r\nImg1 img2\r\nWe tested cases: Maxdepth=30 and Maxdepth=60, the latter has mildly quality improvement\r\n\r\n(2) features to be sampled per train image\r\n\r\nNumber of features per train image is proportional to dimension of b(I) which represents the splits in each node so that decreasing features per train image greatly shortens time while degrade reconstruction image to a slight extend.\r\nImg1 img2\r\nWe tested cases: fperi=5000 V.S. fperi=1000, the latter has negligible inferior quality but far faster than the former.\r\n\r\n**3. Regression features**\r\n\r\nSplit features determine the splits in regression tree which provide description for the classification of pixels with similar characteristics. Regression features are used as predictors which embody properties of the neighborhood and exhibit a strong correlation to the color. \r\nIn the paper, regression features compose texture plus global image features (top pyramid grayscale image intensity) which occasionally brings to bad outcome due to large variation of lightness in image sets as we speculate. Therefore we dropped global image features, leave merely texture image features and obtained better results.\r\n\r\n**4. LEARCH objective function and the Bhattacharyya distance**\r\n\r\nThe final objective function is a weighted sum of LEARCH objective function and the Bhattacharyya distance which ensures spatial coherence while performing histogram correction. The complete objective function denoted as: . Adjusting  influences this trade-off as bigger  provides steeper color variation which displayed below.\r\n\r\n\r\n***\r\n### **Analysis** \r\nNow that you have used this approach, what do you think are its main strengths and weaknesses.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}