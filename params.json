{
  "name": "CSE555 Final Project - Automatic Image Colorization",
  "tagline": "Mengyan Li & Yu He",
  "body": "### **Abstract**\r\nThis project focus on automatic image colorization given a greyscale input image. Different from [Levin et al.'s](http://www.cs.huji.ac.il/%7Eyweiss/Colorization/) approach, and [Image Analogies](http://mrl.nyu.edu/projects/image-analogies/) which rely on user interaction, this project implement a fully automatic colorization method proposed in [Large-scale Learning](http://vision.cs.illinois.edu/projects/lscolor/largescale_automatic_colorization.pdf) which exploits a LEARCH framework to train a quadratic objective function in the chromaticity maps and then colorize the image by minimize this objective function. We modified their code by pruning the regression tree to improve the efficiency and avoid overfitting, and we experiment different parameters, features and histogram correction method. \r\n\r\n***\r\n### **Best result**\r\nThe left are our results, the right are the ground truth.\r\n\r\n![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/best_result.tif) ![ground truth](https://github.com/SuperMonanana/ImageColorization/blob/master/data/c.png?raw=true) \r\n\r\n![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/theirdata.tif) ![](https://github.com/SuperMonanana/ImageColorization/blob/master/data/colorBeach.png?raw=true)\r\n\r\n![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/campus2good.tif)\r\n![](https://github.com/SuperMonanana/ImageColorization/blob/master/data/color_resize.png?raw=true)\r\n\r\n***\r\n### **Problem definition**\r\nIn this project, the input is greyscale image, and the output is the corresponding colorized image. We will also include ground truth image for comparison.\r\n\r\nWe have the input grey-level image and wish to infer the set of color layers, rearrange it into a vector. Our goal is to learn a quadratic optimization problem in the set of color layers. The coefficients of the objective function are conditioned on image features, using a random forest of regression tree. Images are then colorized by minimizing this objective function.\r\n***\r\n### **Related Work**\r\n\r\nThis project is an exploration of Aditya Deshpande, Jason Rock and David Forsyth. _**Learning Large-Scale Automatic Image Colorization.**_ In ICCV, Dec 2015.\r\n\r\n***\r\n### **Algorithm**\r\nWe learn an objective function and optimize it to get the correct colorization.\r\n\r\n![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/objective%20fcn.tiff) \r\n\r\n![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/margin.tiff)\r\n\r\nBasically we followed the code of our reference paper, but we had some attempts in several areas to make a better prediction.\r\n\r\nFor all the following experiments, we have ground truth image:\r\n\r\n![](https://github.com/SuperMonanana/ImageColorization/blob/master/data/colorbeach.png?raw=true)\r\n\r\n**1. Histogram correction**\r\n\r\nDesired target histogram is modeled as Gaussian mixture model and the number of components are equal to the modes obtained by performing mean-shift clustering modes in the histogram of the target images. Then corresponding modes in the histogram of source images are found with known M components of the target histogram and source histogram. In the paper, histogram correction is achieved using the scene specific mean histogram (normalized from training data). 9 noise image together with the one training image are used to compute the mean histogram. We add a fraction of ground-truth histogram from least variation training set so that multi-scene training images have less impact on specific theme result.\r\n\r\nThe left applied mean histogram, the middle applied our modified histogram correction method, and the right is the ground truth.\r\n \r\n![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/test_1_recon_color-hist_1-1.tif) ![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/test_1_recon_color-gt_hist_2-1.tif) \r\n\r\n**2. Parameter experiment**\r\n\r\nFeatures to be sampled per train image\r\n\r\nNumber of features per train image is proportional to dimension of b(I) which represents the splits in each node so that decreasing features per train image greatly shortens time while degrade reconstruction image to a slight extend.\r\n\r\nWe tested cases: fperi=5000 V.S. fperi=1000, the latter has negligible inferior quality but far faster than the former.\r\n\r\n**3. Regression features**\r\n\r\nSplit features determine the splits in regression tree which provide description for the classification of pixels with similar characteristics. Regression features are used as predictors which embody properties of the neighborhood and exhibit a strong correlation to the color. \r\nIn the paper, regression features compose texture plus global image features (top pyramid grayscale image intensity) which occasionally brings to bad outcome due to large variation of lightness in image sets as we speculate. Therefore we dropped global image features, leave merely texture image features and obtained better results.\r\n\r\n**4. LEARCH objective function and the Bhattacharyya distance**\r\n\r\nThe final objective function is a weighted sum of LEARCH objective function and the Bhattacharyya distance which ensures spatial coherence while performing histogram correction. The complete objective function denoted as: bDist = bDist + lambda.*bLearch. Adjusting  influences this trade-off as bigger provides steeper color variation which displayed below.\r\n\r\nLambda=0.5, 5(the original setting in the paper), 50 are applied in the following results. Large lambda prevents modification of colors by histogram correction.\r\n\r\n![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/lambda0.5.tif) ![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/lambda5.tif) ![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/lambda50.tif)\r\n\r\n***\r\n### **Analysis** \r\nFailed case is like this from which we can see the limit of this method.\r\n![](https://raw.githubusercontent.com/SuperMonanana/ImageColorization/master/data/campusfail.tif) ![](https://github.com/SuperMonanana/ImageColorization/blob/master/data/color_failresize.png?raw=true) \r\n\r\nWe suppose it is difficult for this method to predict picture with more depth of field because it is harder to extract features that special enough to represents a patch in regions with more depth which is usually smaller. Also from the successful cases in Best Results section, we found that the performance is always better when predicting the sky because of the bigger contrast between sky and the other parts of the image, which should reflect the grey-image intensity as it is an important split feature. ",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}